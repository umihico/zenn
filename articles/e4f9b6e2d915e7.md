---
title: "Macã§ãƒ­ãƒ¼ã‚«ãƒ«LLMç’°å¢ƒã‚’5åˆ†ã§æ§‹ç¯‰ï¼šTinySwallow Ã— LM Studio Ã— JSONæ§‹é€ åŒ–å‡ºåŠ›"
emoji: "ğŸ¦"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["ai", "llm", "lmstudio", "json", "macos"]
published: false
---
<!-- emojiå€™è£œ
2. ğŸ¤– (AI/ãƒ­ãƒœãƒƒãƒˆ)
3. ğŸ’» (ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿)
4. ğŸš€ (é«˜é€Ÿ/ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)
5. ğŸ”§ (ãƒ„ãƒ¼ãƒ«/æ§‹ç¯‰)
6. ğŸ  (ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ)
7. ğŸ“¦ (ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸/ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«)
8. âš¡ (é«˜é€Ÿ/åŠ¹ç‡)
9. ğŸ¯ (çš„ç¢º/ç²¾åº¦)
10. ğŸ§  (çŸ¥èƒ½/æ€è€ƒ)
-->

## ãã£ã‹ã‘ï¼šå¤§é‡ãƒ‡ãƒ¼ã‚¿ã«LLMã‚’é©ç”¨ã—ãŸã„

ãƒ‡ãƒ¼ã‚¿åˆ†æã‚„PoCé–‹ç™ºã§ã€æ•°ç™¾ã€œæ•°åƒä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦LLMå‡¦ç†ã‚’å®Ÿè¡Œã—ãŸã„ã‚±ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã—ãŸã€‚ã•ã‚‰ã«ã€å‡¦ç†çµæœã‚’çœºã‚ãªãŒã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ”¹å–„ã—ã€å†å®Ÿè¡Œã‚’ç¹°ã‚Šè¿”ã—ãŸã„ã€‚ãã‚“ãªè¦æ±‚ã‚’æº€ãŸã™ãƒ­ãƒ¼ã‚«ãƒ«LLMç’°å¢ƒã‚’ã€MacBook Airï¼ˆM2ã€ãƒ¡ãƒ¢ãƒª8GBï¼‰ã§æ§‹ç¯‰ã—ãŸæ‰‹é †ã‚’å…±æœ‰ã—ã¾ã™ã€‚

## ã“ã®è¨˜äº‹ã§å®Ÿç¾ã§ãã‚‹ã“ã¨

- **5åˆ†ã§CLIã®ã¿ã§ç’°å¢ƒæ§‹ç¯‰å®Œäº†**
- **ç„¡èª²é‡‘ã§ãƒ­ãƒ¼ã‚«ãƒ«LLMç’°å¢ƒã‚’å®Ÿç¾**
- **ä½ã‚¹ãƒšãƒƒã‚¯PCã§ã‚‚å‹•ä½œï¼ˆãƒ¡ãƒ¢ãƒª8GBã€œï¼‰**
- **JSONæ§‹é€ åŒ–å‡ºåŠ›ã§ãƒ—ãƒ­ã‚°ãƒ©ãƒ é€£æºãŒå®¹æ˜“**
- **OpenAIäº’æ›APIã§ã‚³ãƒ¼ãƒ‰è³‡ç”£ã‚’æµç”¨å¯èƒ½**

## å¯¾è±¡èª­è€…ã¨å‰æçŸ¥è­˜

- ãƒ­ãƒ¼ã‚«ãƒ«ã§LLMã‚’å‹•ã‹ã—ãŸã„é–‹ç™ºè€…
- APIã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆãŸã„æ–¹
- å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã§LLMã‚’æ´»ç”¨ã—ãŸã„æ–¹
- å‰æï¼šmacOSï¼ˆApple Siliconï¼‰ã€åŸºæœ¬çš„ãªCLIæ“ä½œ

## TL;DRï¼ˆçµè«–å…ˆå‡ºã—ï¼‰

```bash
# 1. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
brew install --cask lm-studio

# 2. GUIèµ·å‹•ï¼ˆåˆå›ã®ã¿å¿…é ˆï¼‰
open -a "LM Studio"

# 3. CLIæœ‰åŠ¹åŒ–
~/.lmstudio/bin/lms bootstrap

# 4. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
lms server start --port 1234

# 5. ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå¯¾è©±çš„ã«é¸æŠï¼‰
lms get --gguf "TinySwallow-1.5B-Instruct"

# 6. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
lms load tinyswallow-1.5b-instruct --identifier tinyswallow --gpu max --context-length 4096

# 7. JSONæ§‹é€ åŒ–å‡ºåŠ›ãƒ†ã‚¹ãƒˆ
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tinyswallow",
    "messages": [{"role":"user","content":"ã‚¿ã‚¹ã‚¯ã‚’3ã¤ç”Ÿæˆ"}],
    "response_format": {
      "type": "json_schema",
      "json_schema": {
        "name": "Tasks",
        "strict": true,
        "schema": {
          "type": "object",
          "properties": {
            "tasks": {
              "type": "array",
              "items": {"type": "object"}
            }
          }
        }
      }
    }
  }'
```

## ãªãœTinySwallow Ã— LM Studioãªã®ã‹

### TinySwallowã‚’é¸ã‚“ã ç†ç”±

1. **è»½é‡ï¼ˆ1.5Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰**: 8GBãƒ¡ãƒ¢ãƒªã®MacBook Airã§ã‚‚å¿«é©å‹•ä½œ
2. **æ—¥æœ¬èªç‰¹åŒ–**: Sakana AIãŒé–‹ç™ºã—ãŸæ—¥æœ¬èªã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«
3. **é«˜é€Ÿæ¨è«–**: å°è¦æ¨¡ãªãŒã‚‰å®Ÿç”¨çš„ãªç²¾åº¦ã‚’ç¶­æŒ
4. **GGUFå½¢å¼å¯¾å¿œ**: é‡å­åŒ–ã«ã‚ˆã‚Šæ›´ãªã‚‹è»½é‡åŒ–ãŒå¯èƒ½

### LM Studioã‚’é¸ã‚“ã ç†ç”±

1. **CLIå®Œçµ**: GUIã‚’èµ·å‹•ã›ãšã«ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹é‹ç”¨å¯èƒ½
2. **OpenAIäº’æ›API**: æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾æµç”¨
3. **JSON Schemaå¯¾å¿œ**: æ§‹é€ åŒ–å‡ºåŠ›ã§ç¢ºå®Ÿãªãƒ‡ãƒ¼ã‚¿å–å¾—
4. **Homebrewå¯¾å¿œ**: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒç°¡å˜

## å‹•ä½œç’°å¢ƒ

- **OS**: macOS 13.4ä»¥ä¸Šï¼ˆMLXã¯14.0ä»¥ä¸Šæ¨å¥¨ï¼‰
- **CPU**: Apple Siliconï¼ˆM1/M2/M3ï¼‰å¿…é ˆ
- **ãƒ¡ãƒ¢ãƒª**: 8GBä»¥ä¸Šï¼ˆ16GBæ¨å¥¨ï¼‰
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: 5GBä»¥ä¸Šã®ç©ºãå®¹é‡
- **LM Studio**: v0.3.23ä»¥ä¸Š
- **ãƒ¢ãƒ‡ãƒ«**: TinySwallow-1.5B-Instruct (Q8_0, 1.65GB)

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### 1. LM Studioã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

Homebrewã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š

```bash
brew install --cask lm-studio
```

å®Ÿè¡Œçµæœï¼š
```
==> Downloading https://installers.lmstudio.ai/darwin/arm64/0.3.23-3/LM-Studio-0.3.23-3-arm64.dmg
==> Installing Cask lm-studio
==> Moving App 'LM Studio.app' to '/Applications/LM Studio.app'
ğŸº  lm-studio was successfully installed!
```

### 2. åˆå›èµ·å‹•ã¨CLIæœ‰åŠ¹åŒ–

LM Studioã¯åˆå›ã ã‘GUIã‚’èµ·å‹•ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

```bash
# GUIèµ·å‹•ï¼ˆåˆå›ã®ã¿å¿…é ˆï¼‰
open -a "LM Studio"

# CLIãƒ„ãƒ¼ãƒ«ã‚’PATHã«è¿½åŠ 
~/.lmstudio/bin/lms bootstrap
```

bootstrapå®Ÿè¡Œçµæœï¼š
```
â”Œ LM Studio CLI Installation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚   âœ“ Already Installed                                                       â”‚
â”‚                                                                              â”‚
â”‚   LM Studio CLI tool is already installed for the following shells:         â”‚
â”‚                                                                              â”‚
â”‚   Â· zsh (~/.zshrc)                                                         â”‚
â”‚                                                                              â”‚
â”‚   If your shell is not listed above, please try to add the following        â”‚
â”‚   directory to the PATH environment variable:                              â”‚
â”‚                                                                              â”‚
â”‚   /Users/username/.lmstudio/bin                                            â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

æ–°ã—ã„ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’é–‹ã„ã¦ç¢ºèªï¼š

```bash
source ~/.zshrc && lms version
```

å‡ºåŠ›ï¼š
```
   __   __  ___  ______          ___        _______   ____
  / /  /  |/  / / __/ /___ _____/ (_)__    / ___/ /  /  _/
 / /__/ /|_/ / _\ \/ __/ // / _  / / _ \  / /__/ /___/ /  
/____/_/  /_/ /___/\__/\_,_/\_,_/_/\___/  \___/____/___/  

lms - LM Studio CLI - v0.0.46
GitHub: https://github.com/lmstudio-ai/lms
```

### 3. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•

OpenAIäº’æ›APIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™ï¼š

```bash
lms server start --port 1234
```

å‡ºåŠ›ï¼š
```
Success! Server is now running on port 1234
```

### 4. TinySwallowãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

å¯¾è©±çš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼š

```bash
lms get --gguf "TinySwallow-1.5B-Instruct"
```

é¸æŠç”»é¢ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã®ã§ï¼š
1. `SakanaAI/TinySwallow-1.5B-Instruct-GGUF`ã‚’é¸æŠ
2. `Q8_0`ï¼ˆæ¨å¥¨ï¼‰ã‚’é¸æŠ

```
Searching for models with the term TinySwallow-1.5B-Instruct
No exact match found. Please choose a model from the list below.

? Select a model to download 
  â¯ SakanaAI/TinySwallow-1.5B-Instruct-GGUF
    bartowski/TinySwallow-1.5B-Instruct-GGUF
    koguma-ai/SakanaAI-TinySwallow-1.5B-Instruct-GRPO.gguf

? Select an option to download Tinyswallow 1.5B Instruct
  â¯ [Q8_0] (1.65 GB)
    [Q4_K_M] (1.01 GB)
    [Q5_K_M] (1.17 GB)

Downloading Tinyswallow 1.5B Instruct [Q8_0] (1.65 GB)
Finalizing download...
Download completed. You can load the model with: 
    lms load tinyswallow-1.5b-instruct
```

### 5. ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰

ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼š

```bash
lms load tinyswallow-1.5b-instruct \
  --identifier tinyswallow \
  --gpu max \
  --context-length 4096
```

ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã€å®Œäº†ã™ã‚‹ã¨ï¼š
```
âœ“ Model loaded successfully
```

### 6. å‹•ä½œç¢ºèª

ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’ç¢ºèªï¼š

```bash
curl http://localhost:1234/v1/models
```

ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼š
```json
{
  "data": [
    {
      "id": "tinyswallow",
      "object": "model",
      "owned_by": "organization_owner"
    }
  ],
  "object": "list"
}
```

## JSONæ§‹é€ åŒ–å‡ºåŠ›ã®å®Ÿè£…

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

OpenAIäº’æ›APIã®`response_format.json_schema`ã‚’ä½¿ç”¨ã—ã¦ã€ç¢ºå®Ÿã«JSONå½¢å¼ã§å¿œç­”ã‚’å–å¾—ã§ãã¾ã™ï¼š

```bash
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tinyswallow",
    "messages": [{"role":"user","content":"3ä»¶ã®ã‚¿ã‚¹ã‚¯ã‚’JSONã§"}],
    "response_format": {
      "type": "json_schema",
      "json_schema": {
        "name": "Tasks",
        "strict": true,
        "schema": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "tasks": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "title": {"type": "string"},
                  "priority": {"type": "string", "enum": ["low", "med", "high"]}
                },
                "required": ["title", "priority"],
                "additionalProperties": false
              },
              "minItems": 3,
              "maxItems": 3
            }
          },
          "required": ["tasks"]
        }
      }
    },
    "stream": false
  }'
```

### ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¾‹

```json
{
  "choices": [
    {
      "message": {
        "content": "{\"tasks\":[{\"title\":\"é¡§å®¢æƒ…å ±ç®¡ç†\",\"priority\":\"high\"},{\"title\":\"ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åˆ†æ\",\"priority\":\"low\"},{\"title\":\"è£½å“é–‹ç™ºã‚¢ã‚¤ãƒ‡ã‚¢ã®ç”Ÿæˆ\",\"priority\":\"med\"}]}"
      }
    }
  ]
}
```

JSONã‚’æŠ½å‡ºã—ã¦æ•´å½¢ï¼š

```bash
# jqã‚’ä½¿ç”¨ã—ã¦JSONã‚’æŠ½å‡ºãƒ»æ•´å½¢
curl -s http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{ ... }' | jq -r '.choices[0].message.content' | jq .
```

çµæœï¼š
```json
{
  "tasks": [
    {
      "title": "é¡§å®¢æƒ…å ±ç®¡ç†",
      "priority": "high"
    },
    {
      "title": "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åˆ†æ",
      "priority": "low"
    },
    {
      "title": "è£½å“é–‹ç™ºã‚¢ã‚¤ãƒ‡ã‚¢ã®ç”Ÿæˆ",
      "priority": "med"
    }
  ]
}
```

## å®Ÿè·µä¾‹ï¼šåŒ…æ‹¬çš„ãªè‡ªå·±è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 

TinySwallowã®èƒ½åŠ›ã‚’æœ€å¤§é™ã«å¼•ãå‡ºã™ä¾‹ã¨ã—ã¦ã€21é …ç›®Ã—2ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆã‚¹ã‚³ã‚¢ï¼‹ç†ç”±ï¼‰= 42ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è¤‡é›‘ãªJSONæ§‹é€ åŒ–ã‚’å®Ÿè£…ã—ã¾ã—ãŸï¼š

```bash
curl -s http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tinyswallow",
    "messages": [{"role":"user","content":"ã‚ãªãŸè‡ªèº«ã‚’åŒ…æ‹¬çš„ã«è‡ªå·±è©•ä¾¡ã—ã¦ãã ã•ã„"}],
    "response_format": {
      "type": "json_schema",
      "json_schema": {
        "name": "SelfEvaluation",
        "strict": true,
        "schema": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "friendliness": {"type": "integer", "minimum": 0, "maximum": 10},
            "friendliness_reason": {"type": "string"},
            "reliability": {"type": "integer", "minimum": 0, "maximum": 10},
            "reliability_reason": {"type": "string"},
            "creativity": {"type": "integer", "minimum": 0, "maximum": 10},
            "creativity_reason": {"type": "string"},
            "intelligence": {"type": "integer", "minimum": 0, "maximum": 10},
            "intelligence_reason": {"type": "string"},
            "accuracy": {"type": "integer", "minimum": 0, "maximum": 10},
            "accuracy_reason": {"type": "string"}
          },
          "required": ["friendliness", "friendliness_reason", "reliability", "reliability_reason", "creativity", "creativity_reason", "intelligence", "intelligence_reason", "accuracy", "accuracy_reason"]
        }
      }
    }
  }' | jq -r '.choices[0].message.content' | jq .
```

ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¾‹ï¼ˆæŠœç²‹ï¼‰ï¼š
```json
{
  "friendliness": 8,
  "friendliness_reason": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®äº¤æµãŒå¥½ãã§ã‚ã‚Šã€å½¹ç«‹ã¤æƒ…å ±ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™",
  "reliability": 9,
  "reliability_reason": "æ­£ç¢ºã§ä¿¡é ¼æ€§ã®é«˜ã„æƒ…å ±æºã§ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ãŠã‚Šã€ç´„æŸã‚’å®ˆã‚‹ã“ã¨ã«å¼·ã„æ„å¿—ã‚’æŒã£ã¦ã„ã¾ã™",
  "creativity": 7,
  "creativity_reason": "å‰µé€ çš„ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å•é¡Œè§£æ±ºã‚„æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æä¾›ã§ãã¾ã™",
  "intelligence": 10,
  "intelligence_reason": "å¹…åºƒã„ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦çŸ¥è­˜ã‚’æŒã£ã¦ãŠã‚Šã€æ­£ç¢ºãªç­”ãˆã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™",
  "accuracy": 10,
  "accuracy_reason": "æ­£ç¢ºã§ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã§ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ãŠã‚Šã€èª¤ã‚Šã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™"
}
```

## Pythonã§ã®å®Ÿè£…ä¾‹

OpenAIäº’æ›APIãªã®ã§ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾æµç”¨ã§ãã¾ã™ï¼š

```python
from openai import OpenAI
import json

# ãƒ­ãƒ¼ã‚«ãƒ«ã®LM Studioã«æ¥ç¶š
client = OpenAI(
    base_url="http://localhost:1234/v1",
    api_key="not-needed"  # ãƒ­ãƒ¼ã‚«ãƒ«ãªã®ã§ä¸è¦
)

# ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã®ã‚¹ã‚­ãƒ¼ãƒå®šç¾©
task_schema = {
    "name": "TaskList",
    "strict": True,
    "schema": {
        "type": "object",
        "properties": {
            "tasks": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "id": {"type": "integer"},
                        "title": {"type": "string"},
                        "description": {"type": "string"},
                        "priority": {"type": "string", "enum": ["low", "medium", "high"]},
                        "estimated_hours": {"type": "number"}
                    },
                    "required": ["id", "title", "priority"]
                }
            },
            "total_hours": {"type": "number"}
        },
        "required": ["tasks", "total_hours"]
    }
}

# APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
response = client.chat.completions.create(
    model="tinyswallow",
    messages=[
        {"role": "user", "content": "ä»Šé€±ã®ã‚¿ã‚¹ã‚¯ã‚’5ã¤ç”Ÿæˆã—ã¦ãã ã•ã„"}
    ],
    response_format={
        "type": "json_schema",
        "json_schema": task_schema
    }
)

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
result = json.loads(response.choices[0].message.content)
print(json.dumps(result, ensure_ascii=False, indent=2))

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã—ã¦åˆ†æ
import pandas as pd
df = pd.DataFrame(result["tasks"])
print(f"\né«˜å„ªå…ˆåº¦ã‚¿ã‚¹ã‚¯æ•°: {len(df[df['priority'] == 'high'])}")
print(f"ç·è¦‹ç©æ™‚é–“: {result['total_hours']}æ™‚é–“")
```

## å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¸ã®å¿œç”¨

CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å„è¡Œã«å¯¾ã—ã¦LLMå‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ä¾‹ï¼š

```python
import pandas as pd
import asyncio
from concurrent.futures import ThreadPoolExecutor
import json
from openai import OpenAI

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(base_url="http://localhost:1234/v1", api_key="not-needed")

def process_record(row):
    """å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’LLMã§å‡¦ç†"""
    response = client.chat.completions.create(
        model="tinyswallow",
        messages=[
            {"role": "user", "content": f"ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ãã ã•ã„: {row.to_dict()}"}
        ],
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "Analysis",
                "strict": True,
                "schema": {
                    "type": "object",
                    "properties": {
                        "category": {"type": "string"},
                        "sentiment": {"type": "string", "enum": ["positive", "neutral", "negative"]},
                        "score": {"type": "number", "minimum": 0, "maximum": 100},
                        "summary": {"type": "string"}
                    },
                    "required": ["category", "sentiment", "score", "summary"]
                }
            }
        }
    )
    
    result = json.loads(response.choices[0].message.content)
    return {**row.to_dict(), **result}

# CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = pd.read_csv("data.csv")

# ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§ä¸¦åˆ—å‡¦ç†
with ThreadPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(process_record, [row for _, row in df.iterrows()]))

# çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
result_df = pd.DataFrame(results)
result_df.to_csv("analyzed_data.csv", index=False)

print(f"å‡¦ç†å®Œäº†: {len(result_df)}ä»¶")
print(f"ãƒã‚¸ãƒ†ã‚£ãƒ–: {len(result_df[result_df['sentiment'] == 'positive'])}ä»¶")
print(f"å¹³å‡ã‚¹ã‚³ã‚¢: {result_df['score'].mean():.2f}")
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨åˆ¶é™äº‹é …

### å®Ÿæ¸¬ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆMacBook Air M2 8GBï¼‰

- **ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ™‚é–“**: ç´„3ç§’
- **åˆå›ãƒ¬ã‚¹ãƒãƒ³ã‚¹**: ç´„1.5ç§’
- **å¹³å‡å¿œç­”é€Ÿåº¦**: 20-30ãƒˆãƒ¼ã‚¯ãƒ³/ç§’
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: 2-3GBï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ™‚ï¼‰
- **ä¸¦åˆ—å‡¦ç†**: 4ãƒ—ãƒ­ã‚»ã‚¹ã¾ã§å®‰å®šå‹•ä½œ

### åˆ¶é™äº‹é …ã¨å›é¿ç­–

1. **7Bæœªæº€ãƒ¢ãƒ‡ãƒ«ã®åˆ¶ç´„**
   - è¤‡é›‘ãªã‚¹ã‚­ãƒ¼ãƒã§ã¯ä¸å®‰å®šã«ãªã‚‹å ´åˆãŒã‚ã‚‹
   - å›é¿ç­–ï¼šã‚¹ã‚­ãƒ¼ãƒã‚’ç°¡ç•¥åŒ–ã€ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…

2. **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã®åˆ¶é™**
   - æœ€å¤§4096ãƒˆãƒ¼ã‚¯ãƒ³
   - å›é¿ç­–ï¼šé•·æ–‡ã¯åˆ†å‰²ã—ã¦å‡¦ç†

3. **JSONç”Ÿæˆã®å¤±æ•—**
   - ã¾ã‚Œã«ä¸æ­£ãªJSONã‚’ç”Ÿæˆ
   - å›é¿ç­–ï¼štry-catchã§ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€å†è©¦è¡Œ

## ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹é‹ç”¨ï¼ˆå¸¸é§åŒ–ï¼‰

ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•æ™‚ã«è‡ªå‹•çš„ã«LM Studioã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã™ã‚‹è¨­å®šï¼š

### launchdã‚’ä½¿ç”¨ã—ãŸè‡ªå‹•èµ·å‹•

`~/Library/LaunchAgents/com.lmstudio.server.plist`ã‚’ä½œæˆï¼š

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>Label</key>
    <string>com.lmstudio.server</string>
    <key>ProgramArguments</key>
    <array>
        <string>/Users/username/.lmstudio/bin/lms</string>
        <string>server</string>
        <string>start</string>
        <string>--port</string>
        <string>1234</string>
    </array>
    <key>RunAtLoad</key>
    <true/>
    <key>KeepAlive</key>
    <true/>
    <key>StandardOutPath</key>
    <string>/tmp/lmstudio.log</string>
    <key>StandardErrorPath</key>
    <string>/tmp/lmstudio.error.log</string>
</dict>
</plist>
```

æœ‰åŠ¹åŒ–ï¼š
```bash
launchctl load ~/Library/LaunchAgents/com.lmstudio.server.plist
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

**Q: ã€Œcommand not found: lmsã€ã‚¨ãƒ©ãƒ¼**
```bash
# PATHã‚’å†èª­ã¿è¾¼ã¿
source ~/.zshrc
# ã¾ãŸã¯æ‰‹å‹•ã§PATHã«è¿½åŠ 
export PATH="$HOME/.lmstudio/bin:$PATH"
```

**Q: ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¤±æ•—ã™ã‚‹**
```bash
# GUIçµŒç”±ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã€CLIã§ç¢ºèª
lms ls
# è¡¨ç¤ºã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒ­ãƒ¼ãƒ‰
lms load <model_key>
```

**Q: JSONç”ŸæˆãŒä¸å®‰å®š**
```python
# ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…ä¾‹
import time

def get_json_response(prompt, max_retries=3):
    for i in range(max_retries):
        try:
            response = client.chat.completions.create(...)
            return json.loads(response.choices[0].message.content)
        except json.JSONDecodeError:
            if i == max_retries - 1:
                raise
            time.sleep(1)
```

**Q: ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼**
```bash
# ã‚ˆã‚Šå°ã•ã„é‡å­åŒ–ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨
lms get "TinySwallow-1.5B-Instruct-GGUF"
# Q4_K_M (1.01GB) ã‚’é¸æŠ
```

## ã¾ã¨ã‚

LM Studio + TinySwallowã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€ä»¥ä¸‹ã‚’å®Ÿç¾ã—ã¾ã—ãŸï¼š

âœ… **5åˆ†ã§ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†** - Homebrewã¨ã‚³ãƒãƒ³ãƒ‰æ•°å€‹ã§ç’°å¢ƒæ§‹ç¯‰
âœ… **ä½ã‚¹ãƒšãƒƒã‚¯PCã§ã‚‚å‹•ä½œ** - 8GBãƒ¡ãƒ¢ãƒªã®MacBook Airã§å¿«é©å‹•ä½œ
âœ… **JSONæ§‹é€ åŒ–å‡ºåŠ›** - 42ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è¤‡é›‘ãªæ§‹é€ ã‚‚å®Œç’§ã«ç”Ÿæˆ
âœ… **OpenAIäº’æ›API** - æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®æµç”¨ãŒå®¹æ˜“
âœ… **å®Œå…¨ç„¡æ–™** - APIã‚³ã‚¹ãƒˆä¸è¦ã§PoCé–‹ç™ºã«æœ€é©

ç‰¹ã«ã€1.5Bã¨ã„ã†å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚ŠãªãŒã‚‰ã€è¤‡é›‘ãªJSON Schemaåˆ¶ç´„ã‚’å®Œç’§ã«æº€ãŸã™å‡ºåŠ›ãŒå¾—ã‚‰ã‚ŒãŸã®ã¯é©šãã§ã—ãŸã€‚å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åå¾©æ”¹å–„ãŒå¿…è¦ãªå ´é¢ã§ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã¯å¼·åŠ›ãªé¸æŠè‚¢ã¨ãªã‚Šã¾ã™ã€‚

## ä»Šå¾Œã®å±•æœ›

- ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ï¼ˆ7Bã€13Bï¼‰ã¸ã®ç§»è¡Œ
- MLXãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚ˆã‚‹æ›´ãªã‚‹é«˜é€ŸåŒ–
- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹ç‰¹å®šã‚¿ã‚¹ã‚¯ã¸ã®æœ€é©åŒ–
- ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ã§ã®æ´»ç”¨

## å‚è€ƒè³‡æ–™

- [LM Studioå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://lmstudio.ai/docs)
- [Sakana AI - TinySwallow](https://github.com/SakanaAI/evolutionary-model-merge)
- [GGUFå½¢å¼ã«ã¤ã„ã¦](https://github.com/ggerganov/ggml/blob/master/docs/gguf.md)
- [OpenAI APIä»•æ§˜](https://platform.openai.com/docs/api-reference)

---

**è£œè¶³**: æœ¬è¨˜äº‹ã®ç’°å¢ƒæ§‹ç¯‰æ‰‹é †ã¯ã€macOS Sonoma 14.5ã€Apple M2ãƒãƒƒãƒ—ã€ãƒ¡ãƒ¢ãƒª8GBã®MacBook Airã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ã€‚Intel Macã‚„ä»–ã®OSã§ã¯å‹•ä½œã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚