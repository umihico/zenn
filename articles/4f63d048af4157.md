---
title: "RDSã®DBãƒ‡ãƒ¼ã‚¿ã¯å…¨ã¦BigQueryã«åŒæœŸã—ã¦åˆ†æåŸºç›¤ã‚’æ•´ãˆã¦ã„ã‚‹è©±"
emoji: "ğŸ§˜"
type: "tech"
topics: ["bigquery", "aws", "terraform", "githubactions", "dataengineering"]
published: true
publication_name: "studio_prairie"
---

# TL;DR

AWS RDSã®å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’GCP BigQueryã«æ—¥æ¬¡åŒæœŸã™ã‚‹ä»•çµ„ã¿ã‚’GitHub Actionsã¨Terraformã§å†…è£½ã—ãŸè¨˜éŒ²ã§ã™ã€‚ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¿½åŠ ã«ã‚‚è‡ªå‹•ã§åŒæœŸã—ã¾ã™ã€‚

# å¯¾è±¡èª­è€…

- AWS RDSã®ãƒ‡ãƒ¼ã‚¿ã‚’GCP BigQueryã§åˆ†æã™ã‚‹ä»•çµ„ã¿ã‚’æ•´ãˆãŸã„æ–¹

# ã¯ã˜ã‚ã«

ãƒ—ãƒ¬ãƒ¼ãƒªãƒ¼ã‚«ãƒ¼ãƒ‰ã¯Railsã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€AWS RDSã®PostgreSQLã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦åˆ©ç”¨ã—ã¦ã„ã¾ã™ã€‚ãã—ã¦ãƒ‡ãƒ¼ã‚¿åˆ†æã®ãŸã‚ã«ã€RDSã®ãƒ‡ãƒ¼ã‚¿ã‚’BigQueryã«æ—¥æ¬¡ã§åŒæœŸã™ã‚‹ä»•çµ„ã¿ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™ã€‚BigQueryã‚’ä½¿ã†ã“ã¨ã§ã€BIãƒ„ãƒ¼ãƒ«Looker Studioã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã‚„ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ä»¥å¤–ã§ã‚‚AIã‚’é§†ä½¿ã—ã¦ã‚¯ã‚¨ãƒªã‚’æ›¸ã„ã¦åˆ†æã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

# å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

## å‡¦ç†ãƒ•ãƒ­ãƒ¼

BQã¸ã®åŒæœŸå‡¦ç†ã¯GitHub Actionsã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚Œã¦ãŠã‚Šã€3æ™‚é–“ã”ã¨ã«å„ã‚¹ãƒ†ãƒƒãƒ—ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚æ—¥ä»˜ãŒå¤‰ã‚ã‚‹0æ™‚éãã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒå–ã‚‰ã‚Œã¦ã‹ã‚‰ã€ãã‚Œã‚’ä½¿ã„æœã®9æ™‚ã«ã¯ãƒ‡ãƒ¼ã‚¿ã®åŒæœŸã‚’å®Œäº†ã•ã›ã‚‹è¨­è¨ˆã§ã™ã€‚

1. **00:00 JST**: RDSã®è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒé–‹å§‹
2. **03:00 JST**: GitHub Actionsã§RDSã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’S3ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’å®Ÿè¡Œ
3. **06:00 JST**: Github Actionsã§Terraformã‚’å®Ÿè¡Œã—ã€BigQuery Data Transfer Serviceã§S3ã‹ã‚‰BigQueryã¸è»¢é€
4. **09:00 JST**: ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãåŒæœŸã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯


## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³

```mermaid
graph LR
    subgraph AWS
        RDS[RDS<br/>PostgreSQL]
        Snapshot[RDS Snapshot]
        S3[S3 Bucket<br/>Parquetå½¢å¼]
    end
    
    subgraph GitHub
        Actions[GitHub Actions<br/>Scheduler]
    end
    
    subgraph GCP
        DTS[BigQuery<br/>Data Transfer Service<br/>06:00 JST]
        BQ[BigQuery<br/>Dataset]
    end
    
    RDS -->|00:00 JST è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—| Snapshot
    Actions -->|03:00 JST ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆé–‹å§‹| Snapshot
    Snapshot -->|ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ| S3
    Actions -->|06:00 JST Terraformå®Ÿè¡Œã«ã‚ˆã‚Šè»¢é€| DTS
    S3 -->|è»¢é€| DTS
    DTS -->|S3ã‹ã‚‰BQã¸è»¢é€| BQ
    Actions -->|09:00 JST ãƒ‡ãƒ¼ã‚¿è»¢é€å®Œäº†ã‚’æ¤œè¨¼| BQ
    
    style RDS fill:#FF9900
    style S3 fill:#FF9900
    style Actions fill:#6e7681
    style BQ fill:#4285F4
    style DTS fill:#4285F4
```

# å®Ÿè£…è©³ç´°

## GitHub Actionsã®è¨­å®š

GitHub Actionsã§ã¯ã€3ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’scheduleã¨workflow_dispatchã§å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ï¼š

```yaml
name: BigQuery Sync Workflow

on:
  workflow_dispatch:
    inputs:
      step:
        required: false
        default: "health-check"
  schedule:
    - cron: "00 19 * * *" # 3am RDSã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’S3ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹
    - cron: "00 22 * * *" # 6am Terraformã‚’å®Ÿè¡Œã—ã€BigQuery Data Transfer Serviceã§S3ã‹ã‚‰BigQueryã¸è»¢é€
    - cron: "00 1 * * *"  # 9am ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãåŒæœŸã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

jobs:
  terraform:
    env:
      START_EXPORTING: ${{ (github.event.schedule == '00 19 * * *' || github.event.inputs.step == 'export') && 'yes' || 'no' }}
      START_TERRAFORM: ${{ (github.event.schedule == '00 22 * * *' || github.event.inputs.step == 'terraform') && 'yes' || 'no' }}
      START_HEALTH_CHECK: ${{ (github.event.schedule == '00 1 * * *' || github.event.inputs.step == 'health-check') && 'yes' || 'no' }}
```

### ã‚¹ãƒ†ãƒƒãƒ— 1: RDSã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

RDSã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’S3ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹å‡¦ç†ã§ã™ã€‚

```yaml
- name: Clean previous export, and Move export files
  if: env.START_EXPORTING == 'yes'
  run: |
    # å‰å›ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    aws s3 rm s3://my-rds-export-bucket/rds-export-task-for-bq --recursive
    
    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè­˜åˆ¥å­ã‚’ç”Ÿæˆï¼ˆexport-task-identifierã®é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
    echo dump-$(date +%s) | aws s3 cp - s3://my-rds-export-bucket/scripts/dir_identifier.txt --content-type text/plain
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
    aws s3 cp s3://my-rds-export-bucket/scripts/start_export_task_command.sh - | bash
    
    # æ—¥ä»˜ã‚­ãƒ¼ã‚’ä¿å­˜ï¼ˆBigQuery Data Transfer Serviceã§ä½¿ç”¨ï¼‰
    echo $(date +%Y%m%d) | aws s3 cp - s3://my-rds-export-bucket/scripts/date_key.txt --content-type text/plain
```

### ã‚¹ãƒ†ãƒƒãƒ— 2: Terraform Apply

GCPã®Data Transfer Serviceã§ã¯ã€DBä¸¸ã”ã¨(=å…¨ãƒ†ãƒ¼ãƒ–ãƒ«)ã‚’è»¢é€ã™ã‚‹ä¾¿åˆ©ãªæŒ‡ç¤ºã¯ã§ããªã„ã®ã§ã€ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’ã‚¯ã‚¨ãƒªã‹ã‚‰ç„¡ç†ã‚„ã‚Šå–å¾—ã—ã¦ã„ã¾ã™ã€‚

```yaml
- name: Update table list
  if: env.START_TERRAFORM == 'yes'
  run: |
    # RDSã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’æŠ½å‡º
    aws s3 cp s3://my-rds-export-bucket/$(aws s3api list-objects-v2 \
      --bucket my-rds-export-bucket \
      --prefix "rds-export-task-for-bq/" \
      --query 'Contents[?contains(Key, `export_tables_info_`) && ends_with(Key, `.json`)].Key' \
      --output text) - | jq '.perTableStatus[].target | sub("<DB_NAME>.public."; "")' | jq -s > tables.json
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’S3ã«ä¿å­˜
    aws s3 cp tables.json s3://my-rds-export-bucket/rds-export-task-for-bq/tables.json

- name: Terraform apply
  if: env.START_TERRAFORM == 'yes'
  run: |
    terraform -chdir=only-bq-sync-place init -migrate-state
    terraform -chdir=only-bq-sync-place apply -auto-approve
```

### ã‚¹ãƒ†ãƒƒãƒ— 3: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

BigQueryã«æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ãŒåŒæœŸã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ã„ã¾ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ã§ç‰¹å®šã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®æœ€å¤§ã®created_atã‚’å–å¾—ã—ã¦ã€24æ™‚é–“ä»¥ä¸ŠçµŒã£ã¦ã„ãŸã‚‰åŒæœŸå¤±æ•—ã¨ã—ã¦Slacké€šçŸ¥ã—ã¾ã™ã€‚

```yaml
- name: Health check
  if: env.START_HEALTH_CHECK == 'yes'
  run: |
    bq_last_time=$(bq query --use_legacy_sql=false --format=csv 'SELECT created_at FROM `<DATASET_NAME>.<TABLE_NAME>` ORDER BY created_at DESC LIMIT 1' | tail -n 1)
    echo "bq_last_time: $bq_last_time"
    bq_last_time=$(date -d "$bq_last_time" +%s)
    now=$(date +%s)
    diff=$((now - bq_last_time))
    if [ $diff -gt 86400 ]; then
      echo "Data is not updated in 24 hours: $diff"
      exit 1
    fi
```

## Terraformã®è¨­å®š

### RDSã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¿ã‚¹ã‚¯ã®ç”Ÿæˆ

Terraformã§ã¯ã€RDSã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ã‚’å‹•çš„ã«ç”Ÿæˆï¼š

```hcl
locals {
  start_export_task_command = <<-EOT
    aws rds start-export-task \
        --s3-prefix rds-export-task-for-bq \
        --export-task-identifier $(aws s3 cp s3://${aws_s3_object.dir_identifier.bucket}/${aws_s3_object.dir_identifier.key} -)-$(date +%Y%m%d) \
        --source-arn $(aws rds describe-db-snapshots --db-instance-identifier ${data.aws_db_instance.rds.db_instance_identifier} --query "reverse(sort_by(DBSnapshots, &SnapshotCreateTime))[0].DBSnapshotArn" --output text) \
        --s3-bucket-name ${aws_s3_bucket.rds_export_bucket.bucket} \
        --iam-role-arn ${aws_iam_role.rds_export_role.arn} \
        --kms-key-id ${aws_kms_key.rds_export_key.arn}
  EOT
}
```

ã“ã®ã‚³ãƒãƒ³ãƒ‰ã®å·¥å¤«ç‚¹ã¨ã—ã¦ã€ã¾ãšRDSã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã¯æ—¥æ¬¡ã§è¤‡æ•°ä½œæˆã•ã‚Œã‚‹ãŸã‚ã€`describe-db-snapshots`ã§å–å¾—ã—ãŸä¸€è¦§ã‚’ä½œæˆæ™‚åˆ»ã§ã‚½ãƒ¼ãƒˆã—ã€æœ€æ–°ã®ã‚‚ã®ã‚’è‡ªå‹•é¸æŠã™ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚

ã¾ãŸã€AWSã®export-task-identifierã¯ä¸€åº¦ä½¿ç”¨ã—ãŸå€¤ã‚’å†åˆ©ç”¨ã§ããªã„ä»•æ§˜ãŒã‚ã‚‹ãŸã‚ã€S3ã«ä¿å­˜ã—ãŸãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè­˜åˆ¥å­ã¨ãã®æ—¥ã®æ—¥ä»˜ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€æ¯å›ç•°ãªã‚‹IDã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å†å®Ÿè¡Œæ™‚ã®ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã§ãã¾ã™ã€‚

### è‡ªå‹•åŒæœŸã®ä»•çµ„ã¿

ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¿½åŠ ã•ã‚Œã¦ã‚‚è‡ªå‹•çš„ã«åŒæœŸã•ã‚Œã‚‹ä»•çµ„ã¿ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚å‰Šé™¤ã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã¯Terraformå´ã§state rmã—ã¦ã€åŸºæœ¬çš„ã«ã¯BQä¸Šã«ã¯æ®‹ã—ã¦ãŠãé‹ç”¨ã«ã—ã¦ã„ã¾ã™ã€‚

```hcl
# S3ã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
data "aws_s3_object" "tables" {
  bucket = aws_s3_bucket.rds_export_bucket.bucket
  key    = "rds-export-task-for-bq/tables.json"
}

locals {
  tables = toset(jsondecode(data.aws_s3_object.tables.body))
}

# å‹•çš„ã«ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
resource "google_bigquery_table" "main" {
  for_each = local.tables

  dataset_id          = data.google_bigquery_dataset.main.dataset_id
  table_id            = each.key
  deletion_protection = true
}

# å„ãƒ†ãƒ¼ãƒ–ãƒ«ã«å¯¾ã—ã¦Data Transfer Configã‚’ä½œæˆ
resource "google_bigquery_data_transfer_config" "main" {
  for_each = local.tables

  display_name           = each.key
  location               = "asia-northeast1"
  data_source_id         = "amazon_s3"
  schedule               = "every 48 hours"
  destination_dataset_id = data.google_bigquery_dataset.main.dataset_id
  params = {
    destination_table_name_template = google_bigquery_table.main[each.key].table_id
    data_path = "s3://${aws_s3_bucket.rds_export_bucket.bucket}/rds-export-task-for-bq/${chomp(data.aws_s3_object.dir_identifier.body)}-${trimspace(data.aws_s3_object.date_key.body)}/<DB_NAME>/public.${each.key}/1/*.parquet"
    access_key_id     = aws_iam_access_key.bq_data_transfer_user_access_key.id
    secret_access_key = aws_iam_access_key.bq_data_transfer_user_access_key.secret
    file_format       = "PARQUET"
    write_disposition = "WRITE_TRUNCATE"
  }
}
```

é€šå¸¸ã€æ–°ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¿½åŠ ã•ã‚Œã‚‹ãŸã³ã«æ‰‹å‹•ã§BigQueryã®ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã‚„è»¢é€è¨­å®šã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã¨é‡ã„ã¾ã™ãŒã€ã“ã®ä»•çµ„ã¿ã§RDSã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ™‚ã«ç”Ÿæˆã•ã‚Œã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’è‡ªå‹•çš„ã«èª­ã¿å–ã‚Šã€ã“ã®å‹•çš„ãªãƒ†ãƒ¼ãƒ–ãƒ«ãƒªã‚¹ãƒˆã«åŸºã¥ã„ã¦å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚èª¤æ“ä½œã§ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå‰Šé™¤ã•ã‚Œã¦ã—ã¾ã‚ãªã„ã‚ˆã†ã€`deletion_protection = true` ã‚’è¨­å®šã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ„å›³ã—ãªã„ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤ã‚’é˜²ãã¤ã¤ã€æŸ”è»Ÿãªé‹ç”¨ãŒå¯èƒ½ã«ãªã£ã¦ã„ã¾ã™ã€‚

### è»¢é€ã®å¼·åˆ¶å®Ÿè¡Œ

BigQuery Data Transfer Serviceã¯é€šå¸¸ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã§ã™ãŒã€å–å¾—å…ˆã®S3ã®ãƒ‘ã‚¹ãŒå¤‰ã‚ã£ã¦Terraform applyæ™‚ã«å³åº§ã«å®Ÿè¡Œã•ã›ã‚‹ãŸã‚ã«å¸¸ã«ãƒªã‚½ãƒ¼ã‚¹ã‚’å†ä½œæˆã—ã¦ã„ã¾ã™ã€‚æ¯æ—¥å†ä½œæˆã—ã¦ã„ã‚‹ãŸã‚ã€æŒ‡å®šã—ã¦ã„ã‚‹å±æ€§`every 48 hours`ã¯å®Ÿéš›ã«ã¯ä½¿ã‚ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

```hcl
resource "null_resource" "always_run" {
  triggers = {
    timestamp = "${timestamp()}"
  }
}

resource "google_bigquery_data_transfer_config" "main" {
  # ...
  lifecycle {
    replace_triggered_by = [
      null_resource.always_run
    ]
  }
}
```

# ç¾åœ¨ã®èª²é¡Œã¨ä»Šå¾Œã®å±•æœ›

å…ƒã€…ã¯RDSã¨BQé–“ã®åŒæœŸã¯Fivetranã‚’åˆ©ç”¨ã—ã¦ä¸¸æŠ•ã’ã—ã¦ã„ã¾ã—ãŸãŒã€ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®šã§ä¸€åº¦ä¸æ•´åˆãŒèµ·ãã¦ã—ã¾ã£ãŸå¾Œã«ã€FivetranãŒã†ã¾ãå‹•ä½œã§ããšç°¡å˜ã«è§£æ¶ˆã§ãã‚‹è¦‹é€šã—ãŒãªããªã£ãŸãŸã‚ã€çªè²«å·¥äº‹ã§åŒæœŸã™ã‚‹ä»•çµ„ã¿ã‚’ä½œã‚Šãƒªãƒ—ãƒ¬ã‚¤ã‚¹ã—ã¾ã—ãŸã€‚ã‚¹ãƒ”ãƒ¼ãƒ‰å„ªå…ˆã§ç¾åœ¨ã¯æ¯æ—¥å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’è»¢é€ã™ã‚‹æ§‹æˆã«ç”˜ã‚“ã˜ã¦ã„ã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿é‡ã®å¢—åŠ ã™ã‚‹ãŸã³ã«èª²é‡‘ãŒå¤§ãããªã‚‹ã®ã§å·®åˆ†ã®ã¿ã®è»¢é€ã«åˆ‡ã‚Šæ›¿ãˆãŸã„ã§ã™ã€‚è¨˜äº‹ã®é€šã‚Šæ­£è¦ã®å®Ÿè£…ã‚‰ã—ã‹ã‚‰ã¬è’ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ç®‡æ‰€ã‚‚è¤‡æ•°ã‚ã‚Šã€ãã“ã‚‚æ•´ãˆãŸã„ã§ã™ã€‚
